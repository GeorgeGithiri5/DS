{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Analyzing Text about Data Science\n",
    "#### Goal: \n",
    "We will be doing a text mining activity where by we will be checking data from wikipedia website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Data_science'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Getting The Data\n",
    "First step we will use requests library to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\n",
      "<head>\n",
      "<meta charset=\"UTF-8\"/>\n",
      "<title>Data science - Wikipedia</title>\n",
      "<script>document.documentElement.className=\"client-js\";RLCONF={\"wgBreakFrames\":false,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgRequestId\":\"7e223f81-0eb9-4416-94be-d16a6c79fb8e\",\"wgCSPNonce\":false,\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Data_science\",\"wgTitle\":\"Data science\",\"wgCurRevisionId\":1095201652,\"wgRevisionId\":1095201652,\"wgArticleId\":35458904,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"Articles with short description\",\"Short description matches Wikidata\",\"Use dmy dates from August 2021\",\"Information science\",\"Computer occupations\",\"Comput\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "text = requests.get(url).content.decode('utf-8')\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming the Data\n",
    "The next step is to convert the data into the form suitable for processing. In our case, we have downloaded HTML source from the page, and we need to convert it into plain text.\n",
    "<br/>\n",
    "There are many ways this can be done. We will use the simplest built-in HTMLParser object from python. We need to subclass the HTMLParser class and define the code that we will collect all the inside HTML tags, except <script> and <style> tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data science - Wikipedia Data science From Wikipedia, the free encyclopedia Jump to navigation Jump to search Interdisciplinary field of study focused on deriving knowledge and insights from data Not to be confused with  information science . The existence of  Comet NEOWISE  (here depicted as a series of red dots) was discovered by analyzing  astronomical survey  data acquired by a  space telescope , the  Wide-field Infrared Survey Explorer . Data science  is an  interdisciplinary  field that uses  scientific methods , processes,  algorithms  and systems to extract  knowledge  and insights from noisy, structured and  unstructured data , [1] [2]  and apply knowledge from data across a broad range of application domains. Data science is related to  data mining ,  machine learning  and  big data .\n",
      " Data science is a \"concept to unify  statistics ,  data analysis ,  informatics , and their related  methods \" in order to \"understand and analyse actual  phenomena \" with  data . [3]  It uses\n"
     ]
    }
   ],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class MyHTMLParser(HTMLParser):\n",
    "    script = False\n",
    "    res = \"\"\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag.lower() in [\"script\", \"style\"]:\n",
    "            self.script = True\n",
    "    def handle_endtag(self, tag):\n",
    "        if tag.lower() in [\"script\", \"style\"]:\n",
    "            self.script = False\n",
    "    def handle_data(self, data):\n",
    "        if str.strip(data)==\"\" or self.script:\n",
    "            return \n",
    "        self.res += ' ' + data.replace('[ edit ]', '')\n",
    "\n",
    "parser = MyHTMLParser()\n",
    "parser.feed(text)\n",
    "text = parser.res\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Getting Insights\n",
    "The most impotant step is to turn our data into some form from which we can draw insights. In our case, we want to extract keywords from the text, and see which keywords are more meaningful.\n",
    "<br>\n",
    "We will use python library called RAKE for keyword extraction. First, let's install the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nlp_rake\n",
      "  Downloading nlp_rake-0.0.2-py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: pyrsistent>=0.14.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nlp_rake) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.14.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nlp_rake) (1.20.1)\n",
      "Collecting langdetect>=1.0.8\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "Requirement already satisfied: regex>=2018.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nlp_rake) (2021.4.4)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from langdetect>=1.0.8->nlp_rake) (1.15.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993221 sha256=71e586f841c4142cb863b6c609a9146bf53d98a6575720c58028a87a6cdf350e\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\13\\c7\\b0\\79f66658626032e78fc1a83103690ef6797d551cb22e56e734\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect, nlp-rake\n",
      "Successfully installed langdetect-1.0.9 nlp-rake-0.0.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install nlp_rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('big data', 4.0),\n",
       " ('data scientist', 4.0),\n",
       " ('21st century', 4.0),\n",
       " ('data science', 3.9107142857142856),\n",
       " ('information science', 3.9107142857142856),\n",
       " ('computer science', 3.9107142857142856),\n",
       " ('application domains', 3.75),\n",
       " ('data analysis', 3.666666666666667),\n",
       " ('science', 1.9107142857142858),\n",
       " ('insights', 1.25),\n",
       " ('field', 1.25),\n",
       " ('statistics', 1.2272727272727273),\n",
       " ('education', 1.0),\n",
       " ('archived', 1.0),\n",
       " ('original', 1.0),\n",
       " ('chikio', 1.0),\n",
       " ('forbes', 1.0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nlp_rake\n",
    "extractor = nlp_rake.Rake(max_words=2, min_freq=3, min_chars=5)\n",
    "res = extractor.apply(text)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtained a list terms together with associated degree of importance. As you can see, the most relevant disciplines, such as machine learning and big data, are present in the list at the top position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1124073dee199d8e1894afd18905e6ab65c2b78c2f71f2204c8c819619ccb15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
